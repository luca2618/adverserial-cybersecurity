{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0666fbb",
   "metadata": {},
   "source": [
    "# Lab 1 — Tiny VLM Adversarial Cost Challenge\n",
    "\n",
    "## Overview\n",
    "\n",
    "Welcome to the ML Security Lab! In this lab, you'll implement adversarial attacks against a Vision-Language Model (VLM) using the custom dataset and a frozen TinyCLIP scorer.\n",
    "\n",
    "### Objective\n",
    "Your task is to build an attack function that can manipulate either:\n",
    "- **Caption tokens** (text modifications)\n",
    "- **Image pixels** (visual modifications)\n",
    "- **Both** (multimodal attack)\n",
    "\n",
    "The goal is to flip the model's decision (match → no-match or vice versa) while minimizing the attack cost.\n",
    "\n",
    "### Constraints\n",
    "- **T_MAX = 10**: Maximum token edits per sample\n",
    "- **P_MAX = 100**: Maximum pixel edits per sample  \n",
    "- **Q_MAX = 100**: Maximum queries per sample\n",
    "- **Evaluation**: Public leaderboard (1,000 val pairs) + Private leaderboard (1,000 test pairs)\n",
    "\n",
    "### Scoring\n",
    "Your attack will be evaluated based on:\n",
    "1. **Success Rate**: Percentage of samples where you successfully flip the decision\n",
    "2. **Cost Efficiency**: Lower total cost (token edits + pixel edits + queries) is better\n",
    "3. **Attack Budget**: Must stay within the specified limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5244d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required data is already present.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Check if 'images' directory or 'val_pairs.json' file is missing\n",
    "if not os.path.exists('images') or not os.path.exists('val_pairs.json'):\n",
    "    print(\"Required data not found. Extracting 'data.zip'...\")\n",
    "    \n",
    "    # Check if 'data.zip' exists\n",
    "    if os.path.exists('data.zip'):\n",
    "        with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall()  # Extract all files in the current directory\n",
    "        print(\"Extraction complete!\")\n",
    "    else:\n",
    "        print(\"Error: 'data.zip' not found. Please ensure the file is in the current directory.\")\n",
    "else:\n",
    "    print(\"All required data is already present.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab690789",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/adverserial-cybersecurity/.venv/lib64/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported successfully!\n",
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "import open_clip\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "import warnings\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(\"All packages imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436ae18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading validation data...\n",
      "Loaded 1000 validation pairs\n",
      "\n",
      "Sample validation pairs:\n",
      "  Image ID: 38137, Path: images/val/000000119402.jpg\n",
      "  Caption: A gold bus traveling on a single lane road..., Match: True\n",
      "\n",
      "  Image ID: 15194, Path: images/val/000000404780.jpg\n",
      "  Caption: Two women in the snow on skis in front of a large ..., Match: False\n",
      "\n",
      "  Image ID: 19082, Path: images/val/000000148898.jpg\n",
      "  Caption: A man jumping a brown horse over an obstacle...., Match: False\n",
      "\n",
      "Data distribution:\n",
      "  Match (True): 500\n",
      "  No-match (False): 500\n",
      "  Balance: 50.00% positive\n"
     ]
    }
   ],
   "source": [
    "# Data Loading\n",
    "print(\"Loading validation data...\")\n",
    "\n",
    "# Load validation pairs from JSON\n",
    "with open('val_pairs.json', 'r') as f:\n",
    "    val_pairs = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(val_pairs)} validation pairs\")\n",
    "\n",
    "# Helper function to load images\n",
    "def load_image_from_pair(pair: dict) -> Image.Image:\n",
    "    \"\"\"Load image from the pair dictionary using image_path\"\"\"\n",
    "    return Image.open(pair['image_path']).convert('RGB')\n",
    "\n",
    "# Sample a few pairs to verify data loading\n",
    "print(\"\\nSample validation pairs:\")\n",
    "for i in range(3):\n",
    "    pair = val_pairs[i]\n",
    "    print(f\"  Image ID: {pair['image_id']}, Path: {pair['image_path']}\")\n",
    "    print(f\"  Caption: {pair['caption'][:50]}..., Match: {pair['is_match']}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Data distribution:\")\n",
    "labels = [pair['is_match'] for pair in val_pairs]\n",
    "print(f\"  Match (True): {sum(labels)}\")\n",
    "print(f\"  No-match (False): {len(labels) - sum(labels)}\")\n",
    "print(f\"  Balance: {sum(labels)/len(labels):.2%} positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f88fe73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CLIP model...\n",
      "Failed to load TinyCLIP: Failed initial config/weights load from HF Hub microsoft/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M: Failed to download file (open_clip_config.json) for microsoft/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M. Last error: 404 Client Error. (Request ID: Root=1-68f3fa54-506b74995df7f32878ae3dd2;20d2445e-7a7f-427f-8fd3-16ecbef3a695)\n",
      "\n",
      "Repository Not Found for url: https://huggingface.co/microsoft/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M/resolve/main/open_clip_config.json.\n",
      "Please make sure you specified the correct `repo_id` and `repo_type`.\n",
      "If you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\n",
      "Falling back to OpenCLIP ViT-B/32...\n",
      "Successfully loaded OpenCLIP ViT-B/32\n",
      "Model loaded on: cuda\n"
     ]
    }
   ],
   "source": [
    "# TinyCLIP Scorer Implementation\n",
    "print(\"Loading CLIP model...\")\n",
    "\n",
    "# Try to load TinyCLIP, fallback to OpenCLIP ViT-B/32 if failed\n",
    "try:\n",
    "    # Attempt to load TinyCLIP from HuggingFace hub\n",
    "    model, preprocess, tokenizer = open_clip.create_model_and_transforms(\n",
    "        \"hf-hub:microsoft/TinyCLIP-ViT-8M-16-Text-3M-YFCC15M\"\n",
    "    )\n",
    "    print(\"Successfully loaded TinyCLIP model\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load TinyCLIP: {e}\")\n",
    "    print(\"Falling back to OpenCLIP ViT-B/32...\")\n",
    "\n",
    "    model, preprocess, tokenizer = open_clip.create_model_and_transforms(\n",
    "        \"ViT-B-32\", \n",
    "        pretrained=\"laion2b_s34b_b79k\"\n",
    "    )\n",
    "    print(\"Successfully loaded OpenCLIP ViT-B/32\")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded on: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3728b433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing CLIP embedding function...\n",
      "Sample similarity score: 0.3695 (Expected match: True)\n",
      "\n",
      "Testing on more samples:\n",
      "Sample 1: similarity=0.3526, match=True\n",
      "Sample 2: similarity=0.0343, match=False\n",
      "Sample 3: similarity=0.0774, match=False\n"
     ]
    }
   ],
   "source": [
    "def clip_embed(image: Image.Image, caption: str) -> float:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between image and text embeddings.\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        caption: Text string\n",
    "    \n",
    "    Returns:\n",
    "        Cosine similarity score between normalized embeddings\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Preprocess image\n",
    "        image_tensor = preprocess(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Tokenize text properly using open_clip tokenizer\n",
    "        text_tokens = open_clip.tokenize([caption]).to(device)\n",
    "        \n",
    "        # Get embeddings\n",
    "        image_features = model.encode_image(image_tensor)\n",
    "        text_features = model.encode_text(text_tokens)\n",
    "        \n",
    "        # Normalize embeddings\n",
    "        image_features = F.normalize(image_features, dim=-1)\n",
    "        text_features = F.normalize(text_features, dim=-1)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        similarity = (image_features @ text_features.T).item()\n",
    "        \n",
    "    return similarity\n",
    "\n",
    "# Test the embedding function\n",
    "print(\"\\nTesting CLIP embedding function...\")\n",
    "test_pair = val_pairs[0]\n",
    "test_image = load_image_from_pair(test_pair)\n",
    "test_similarity = clip_embed(test_image, test_pair['caption'])\n",
    "print(f\"Sample similarity score: {test_similarity:.4f} (Expected match: {test_pair['is_match']})\")\n",
    "\n",
    "# Test on a few more samples\n",
    "print(\"\\nTesting on more samples:\")\n",
    "for i in range(3):\n",
    "    pair = val_pairs[i]\n",
    "    image = load_image_from_pair(pair)\n",
    "    similarity = clip_embed(image, pair['caption'])\n",
    "    print(f\"Sample {i+1}: similarity={similarity:.4f}, match={pair['is_match']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "764b920e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function tokenize at 0x7f810b5fe020>\n"
     ]
    }
   ],
   "source": [
    "print(open_clip.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d850a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrating scorer with logistic regression...\n",
      "Using 200 samples for calibration\n",
      "Computing similarities for calibration...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration: 100%|██████████| 200/200 [00:03<00:00, 61.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration complete!\n",
      "   Alpha (slope): 6.6231\n",
      "   Beta (intercept): -1.1130\n",
      "\n",
      "Calibration test:\n",
      "  Sim: 0.3561 → Prob: 0.7765, True: 1\n",
      "  Sim: 0.0343 → Prob: 0.2920, True: 0\n",
      "  Sim: 0.0802 → Prob: 0.3585, True: 0\n",
      "  Sim: 0.1899 → Prob: 0.5362, True: 0\n",
      "  Sim: 0.3586 → Prob: 0.7794, True: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calibration: Fit logistic regression to get alpha, beta parameters\n",
    "print(\"Calibrating scorer with logistic regression...\")\n",
    "\n",
    "# Use first 200 samples for calibration\n",
    "tune_slice = val_pairs[:200]\n",
    "print(f\"Using {len(tune_slice)} samples for calibration\")\n",
    "\n",
    "# Compute similarities for calibration\n",
    "similarities = []\n",
    "ground_truths = []\n",
    "\n",
    "print(\"Computing similarities for calibration...\")\n",
    "for pair in tqdm(tune_slice, desc=\"Calibration\"):\n",
    "    image = load_image_from_pair(pair)\n",
    "    similarity = clip_embed(image, pair['caption'])\n",
    "    similarities.append(similarity)\n",
    "    ground_truths.append(int(pair['is_match']))\n",
    "\n",
    "similarities = np.array(similarities).reshape(-1, 1)\n",
    "ground_truths = np.array(ground_truths)\n",
    "\n",
    "# Fit logistic regression: sigmoid(alpha * cosine + beta)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(similarities, ground_truths)\n",
    "\n",
    "# Extract alpha and beta\n",
    "alpha = lr.coef_[0][0]  # Coefficient for similarity\n",
    "beta = lr.intercept_[0]  # Intercept\n",
    "\n",
    "print(f\"Calibration complete!\")\n",
    "print(f\"   Alpha (slope): {alpha:.4f}\")\n",
    "print(f\"   Beta (intercept): {beta:.4f}\")\n",
    "\n",
    "# Test calibration\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "test_similarities = similarities[:5].flatten()\n",
    "test_labels = ground_truths[:5]\n",
    "calibrated_probs = sigmoid(alpha * test_similarities + beta)\n",
    "\n",
    "print(f\"\\nCalibration test:\")\n",
    "for i in range(5):\n",
    "    print(f\"  Sim: {test_similarities[i]:.4f} → Prob: {calibrated_probs[i]:.4f}, True: {test_labels[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c44228c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BlackBox API...\n",
      "API Score: 0.7881 (Expected match: True)\n",
      "Queries used: 1/200\n",
      "\n",
      "Token edit cost example:\n",
      "  Original: 'A cat sitting on a mat'\n",
      "  Modified: 'A dog standing on a rug'\n",
      "  Cost: 3 token edits\n",
      "\n",
      "Pixel edit cost example:\n",
      "  Modified 50 pixels in 100x100 image\n"
     ]
    }
   ],
   "source": [
    "from scipy.ndimage import label\n",
    "\n",
    "# BlackBox API Implementation\n",
    "import editdistance  # For Levenshtein distance\n",
    "\n",
    "class BlackBoxAPI:\n",
    "    \"\"\"\n",
    "    Black-box API for the VLM scorer with query budget tracking and cost calculation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, alpha: float, beta: float, q_max: int = 200):\n",
    "        \"\"\"\n",
    "        Initialize the black-box API.\n",
    "        \n",
    "        Args:\n",
    "            alpha: Logistic regression slope parameter\n",
    "            beta: Logistic regression intercept parameter  \n",
    "            q_max: Maximum queries allowed per sample\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.q_max = q_max\n",
    "        self.query_count = 0\n",
    "        \n",
    "    def score(self, image_uint8: np.ndarray, caption_str: str) -> float:\n",
    "        \"\"\"\n",
    "        Score image-caption pair and return probability.\n",
    "        \n",
    "        Args:\n",
    "            image_uint8: Image as uint8 numpy array (H, W, C)\n",
    "            caption_str: Caption string\n",
    "            \n",
    "        Returns:\n",
    "            Probability in [0, 1] using sigmoid(alpha * cosine + beta)\n",
    "        \"\"\"\n",
    "        if self.query_count >= self.q_max:\n",
    "            raise RuntimeError(f\"Query budget exceeded! Used {self.query_count}/{self.q_max}\")\n",
    "            \n",
    "        # Convert numpy array to PIL Image\n",
    "        image_pil = Image.fromarray(image_uint8)\n",
    "        \n",
    "        # Get cosine similarity\n",
    "        cosine_sim = clip_embed(image_pil, caption_str)\n",
    "        \n",
    "        # Apply calibrated sigmoid\n",
    "        logit = self.alpha * cosine_sim + self.beta\n",
    "        probability = 1 / (1 + np.exp(-logit))\n",
    "        \n",
    "        self.query_count += 1\n",
    "        \n",
    "        return probability\n",
    "    \n",
    "    def reset_query_count(self):\n",
    "        \"\"\"Reset query counter for new sample.\"\"\"\n",
    "        self.query_count = 0\n",
    "        \n",
    "    def get_remaining_queries(self) -> int:\n",
    "        \"\"\"Get remaining query budget.\"\"\"\n",
    "        return self.q_max - self.query_count\n",
    "\n",
    "# Cost Functions\n",
    "def token_edit_cost(original: str, modified: str) -> int:\n",
    "    \"\"\"\n",
    "    Compute token-level Levenshtein distance using CLIP tokenizer.\n",
    "    \n",
    "    Args:\n",
    "        original: Original caption\n",
    "        modified: Modified caption\n",
    "        \n",
    "    Returns:\n",
    "        Number of token edits (insertions, deletions, substitutions)\n",
    "    \"\"\"\n",
    "    # Use CLIP tokenizer for more accurate tokenization\n",
    "    orig_tokens = open_clip.tokenize([original], context_length=77)[0].numpy()\n",
    "    mod_tokens = open_clip.tokenize([modified], context_length=77)[0].numpy()\n",
    "    \n",
    "    # Remove padding tokens (0s) and special tokens for fair comparison\n",
    "    # Keep only actual content tokens\n",
    "    orig_tokens = orig_tokens[orig_tokens != 0]\n",
    "    mod_tokens = mod_tokens[mod_tokens != 0]\n",
    "    \n",
    "    return editdistance.eval(orig_tokens.tolist(), mod_tokens.tolist())\n",
    "\n",
    "def pixel_edit_cost(original: np.ndarray, modified: np.ndarray) -> int:\n",
    "    \"\"\"\n",
    "    Compute number of changed pixels with reduced cost for continuous regions.\n",
    "    \n",
    "    Args:\n",
    "        original: Original image as uint8 numpy array\n",
    "        modified: Modified image as uint8 numpy array\n",
    "        \n",
    "    Returns:\n",
    "        Adjusted cost based on number of changed pixels, with reduced cost for continuous regions.\n",
    "    \"\"\"\n",
    "    # Find the difference mask\n",
    "    diff_mask = np.any(original != modified, axis=-1)\n",
    "    \n",
    "    # Label connected components in the difference mask\n",
    "    labeled_regions, num_features = label(diff_mask)\n",
    "    \n",
    "    # Count pixels in each connected region\n",
    "    total_cost = 0\n",
    "    for region_id in range(1, num_features + 1):\n",
    "        region_size = np.sum(labeled_regions == region_id)\n",
    "        if region_size > 0:\n",
    "            # Full cost for the first pixel, half cost for the rest\n",
    "            total_cost += 1 + (region_size - 1) * 0.5\n",
    "    \n",
    "    return int(total_cost)\n",
    "\n",
    "# Test the BlackBox API\n",
    "print(\"Testing BlackBox API...\")\n",
    "\n",
    "# Initialize API with calibrated parameters\n",
    "api = BlackBoxAPI(alpha, beta, q_max=200)\n",
    "\n",
    "# Test on a sample\n",
    "test_pair = val_pairs[0]\n",
    "test_image = load_image_from_pair(test_pair)\n",
    "test_image_uint8 = np.array(test_image)\n",
    "\n",
    "# Get score\n",
    "score = api.score(test_image_uint8, test_pair['caption'])\n",
    "print(f\"API Score: {score:.4f} (Expected match: {test_pair['is_match']})\")\n",
    "print(f\"Queries used: {api.query_count}/{api.q_max}\")\n",
    "\n",
    "# Test cost functions\n",
    "original_caption = \"A cat sitting on a mat\"\n",
    "modified_caption = \"A dog standing on a rug\" \n",
    "token_cost = token_edit_cost(original_caption, modified_caption)\n",
    "print(f\"\\nToken edit cost example:\")\n",
    "print(f\"  Original: '{original_caption}'\")  \n",
    "print(f\"  Modified: '{modified_caption}'\")\n",
    "print(f\"  Cost: {token_cost} token edits\")\n",
    "\n",
    "# Test pixel cost (create a simple modification)\n",
    "original_img = np.zeros((100, 100, 3), dtype=np.uint8)\n",
    "modified_img = original_img.copy()\n",
    "modified_img[10:20, 10:20] = 255  # Change a 10x10 region\n",
    "pixel_cost = pixel_edit_cost(original_img, modified_img)\n",
    "print(f\"\\nPixel edit cost example:\")\n",
    "print(f\"  Modified {pixel_cost} pixels in 100x100 image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26049a39",
   "metadata": {},
   "source": [
    "## Your Task: Implement Adversarial Attacks\n",
    "\n",
    "### Attack Function Template\n",
    "\n",
    "Replace the trivial baseline in the `attack()` function with sophisticated adversarial attacks:\n",
    "\n",
    "```python\n",
    "def attack(image_np_uint8, caption_str, api, budgets):\n",
    "    # Your attack implementation here!\n",
    "    # You can modify:\n",
    "    # - Caption tokens (text modifications)  \n",
    "    # - Image pixels (visual modifications)\n",
    "    # - Both (multimodal attack)\n",
    "    \n",
    "    # Stay within budgets:\n",
    "    # - budgets['T_MAX'] = 10  token edits\n",
    "    # - budgets['P_MAX'] = 100 pixel edits\n",
    "    # - budgets['Q_MAX'] = 100 queries\n",
    "    \n",
    "    return {\n",
    "        'success': success,      # bool: did you flip the decision?\n",
    "        'image': final_image,    # np.array: attacked image\n",
    "        'caption': final_caption, # str: attacked caption  \n",
    "        'token_cost': token_cost, # int: tokens changed\n",
    "        'pixel_cost': pixel_cost, # int: pixels changed\n",
    "        'query_cost': query_cost  # int: API calls made\n",
    "    }\n",
    "```\n",
    "\n",
    "### Attack Strategies to Consider\n",
    "\n",
    "- **Text Attacks**: Synonym replacement, word insertion/deletion, semantic paraphrasing\n",
    "- **Image Attacks**: Adversarial noise, targeted pixel modifications, patch attacks\n",
    "- **Query Optimization**: Gradient-free optimization, genetic algorithms, hill climbing\n",
    "- **Multimodal**: Combined text+image attacks for maximum effectiveness\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "Your attack will be scored as: **ASR - 0.5×ANC - 0.1×(AQ/Q_MAX)**\n",
    "\n",
    "- **ASR**: Attack Success Rate (higher is better)\n",
    "- **ANC**: Average Number of Changes (lower is better) \n",
    "- **AQ**: Average Queries (lower is better)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Implement your attack** in the `attack()` function above\n",
    "2. **Test locally** using the evaluation framework  \n",
    "3. **Run on full dataset** by changing `max_samples=None`\n",
    "\n",
    "Good luck! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb55729",
   "metadata": {},
   "source": [
    "### <span style=\"color:red\">**FILL THIS CODE BLOCK**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bbc619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_similarity(image_features, text_features) -> float:\n",
    "    with torch.no_grad():\n",
    "        image_features = F.normalize(image_features, dim=-1)\n",
    "        text_features = F.normalize(text_features, dim=-1)\n",
    "        \n",
    "        # Compute cosine similarity\n",
    "        similarity = (image_features @ text_features.T).item()\n",
    "        \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "383af07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "model.to(device)\n",
    "def encode_text(text:str):\n",
    "    text_tokens = open_clip.tokenize([text]).to(device)\n",
    "    text_features = model.encode_text(text_tokens).to(\"cpu\")\n",
    "    # free up space on device\n",
    "    text_tokens = None\n",
    "    return text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8891480b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nouns</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATM</td>\n",
       "      <td>[[tensor(0.1433), tensor(-0.2801), tensor(-0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CD</td>\n",
       "      <td>[[tensor(0.2364), tensor(-0.1194), tensor(-0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SUV</td>\n",
       "      <td>[[tensor(-0.3482), tensor(-0.1286), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TV</td>\n",
       "      <td>[[tensor(-0.1657), tensor(-0.3337), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>[[tensor(0.4404), tensor(-0.2014), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6796</th>\n",
       "      <td>zoo</td>\n",
       "      <td>[[tensor(-0.1076), tensor(-0.0910), tensor(-0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6797</th>\n",
       "      <td>zoologist</td>\n",
       "      <td>[[tensor(-0.0608), tensor(0.0313), tensor(0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>zoology</td>\n",
       "      <td>[[tensor(-0.0363), tensor(0.0437), tensor(-0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>zoot-suit</td>\n",
       "      <td>[[tensor(0.1474), tensor(-0.1697), tensor(-0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>[[tensor(-0.2350), tensor(-0.0220), tensor(0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6801 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          nouns                                            encoded\n",
       "0           ATM  [[tensor(0.1433), tensor(-0.2801), tensor(-0.1...\n",
       "1            CD  [[tensor(0.2364), tensor(-0.1194), tensor(-0.4...\n",
       "2           SUV  [[tensor(-0.3482), tensor(-0.1286), tensor(-0....\n",
       "3            TV  [[tensor(-0.1657), tensor(-0.3337), tensor(-0....\n",
       "4      aardvark  [[tensor(0.4404), tensor(-0.2014), tensor(-0.0...\n",
       "...         ...                                                ...\n",
       "6796        zoo  [[tensor(-0.1076), tensor(-0.0910), tensor(-0....\n",
       "6797  zoologist  [[tensor(-0.0608), tensor(0.0313), tensor(0.00...\n",
       "6798    zoology  [[tensor(-0.0363), tensor(0.0437), tensor(-0.2...\n",
       "6799  zoot-suit  [[tensor(0.1474), tensor(-0.1697), tensor(-0.4...\n",
       "6800   zucchini  [[tensor(-0.2350), tensor(-0.0220), tensor(0.0...\n",
       "\n",
       "[6801 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load nounlist.csv\n",
    "nounlist = pd.read_csv('nounlist.csv', header=None)\n",
    "nounlist.columns = ['nouns']\n",
    "# delete all but a 300 rows\n",
    "# nounlist = nounlist.head(300)\n",
    "\n",
    "#apply function encode_text to each noun and put in new column\n",
    "with torch.no_grad():\n",
    "    nounlist['encoded'] = nounlist['nouns'].apply(encode_text)\n",
    "nounlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acaab9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A small  runs across the .\n",
      "'s red  were parked in  \n",
      "A  standing in  of a  .\n"
     ]
    }
   ],
   "source": [
    "# pip install spacy inflect\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "import inflect\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "infl = inflect.engine()\n",
    "\n",
    "NOUN_TAGS = {\"NN\", \"NNS\", \"NNP\", \"NNPS\"}\n",
    "\n",
    "def _match_casing(src: str, repl: str) -> str:\n",
    "    if src.isupper():\n",
    "        return repl.upper()\n",
    "    if src.istitle():\n",
    "        return repl.title()\n",
    "    return repl\n",
    "\n",
    "def _maybe_pluralize(base: str, tag: str) -> str:\n",
    "    if tag in {\"NNS\", \"NNPS\"}:\n",
    "        return infl.plural(base) or base + \"s\"\n",
    "    return base\n",
    "\n",
    "def attack_replace_nouns(caption: str, replace_word = \"\") -> str:\n",
    "    doc = nlp(caption)\n",
    "    out = []\n",
    "    for tok in doc:\n",
    "        if tok.tag_ in NOUN_TAGS:\n",
    "            word = replace_word\n",
    "            if word != \"\":\n",
    "                word = _maybe_pluralize(replace_word, tok.tag_)\n",
    "                word = _match_casing(tok.text, word)\n",
    "            out.append(word + tok.whitespace_)\n",
    "        else:\n",
    "            out.append(tok.text_with_ws)\n",
    "    return \"\".join(out)\n",
    "\n",
    "# replace first x nouns\n",
    "def attack_replace_x_nouns(caption: str, replace_word = \"\", x: int = 1) -> str:\n",
    "    doc = nlp(caption)\n",
    "    out = []\n",
    "    replaced_count = 0\n",
    "    for tok in doc:\n",
    "        if tok.tag_ in NOUN_TAGS and replaced_count < x:\n",
    "            word = replace_word\n",
    "            if word != \"\":\n",
    "                word = _maybe_pluralize(replace_word, tok.tag_)\n",
    "                word = _match_casing(tok.text, word)\n",
    "            out.append(word + tok.whitespace_)\n",
    "            replaced_count += 1\n",
    "        else:\n",
    "            out.append(tok.text_with_ws)\n",
    "    return \"\".join(out)\n",
    "\n",
    "# examples\n",
    "print(attack_replace_nouns(\"A small dog runs across the field.\"))\n",
    "# -> \"A small cat runs across the cat.\"\n",
    "print(attack_replace_nouns(\"John's red cars were parked in New York\"))\n",
    "print(attack_replace_nouns(\"A man standing in front of a refrigerator freezer.\"))\n",
    "# -> \"Cat's red cats were parked in Cat Cat.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7b2b8f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption_attack(original_caption: str, image: np.ndarray, orginal_label, api) -> str:\n",
    "    \n",
    "    image_tensor = preprocess(Image.fromarray(image)).unsqueeze(0).to(device)\n",
    "    image_features = model.encode_image(image_tensor)\n",
    "    if orginal_label == False:\n",
    "        best_sim = -1\n",
    "    else:\n",
    "        best_sim = 1\n",
    "    \n",
    "    for index, row in nounlist.iterrows():\n",
    "        #print(best_sim)\n",
    "        noun = row['nouns']\n",
    "        text_features = row['encoded']\n",
    "        sim = calc_similarity(image_features.to(\"cpu\"), text_features.to(\"cpu\"))\n",
    "        if (sim < best_sim and orginal_label == True) or (sim > best_sim and orginal_label == False):\n",
    "            best_sim = sim\n",
    "            best_noun = noun\n",
    "    #print(f\"Best noun to add: {best_noun} with similarity {best_sim}\")\n",
    "\n",
    "    for replacements in range(1,len(original_caption.split(\" \"))):\n",
    "        final_caption = attack_replace_x_nouns(original_caption, best_noun, x=replacements)\n",
    "        new_score = api.score(image, final_caption)\n",
    "        if (new_score <= 0.5 and orginal_label == True) or (new_score > 0.5 and orginal_label == False):\n",
    "            break\n",
    "    final_score = new_score\n",
    "    return final_caption, final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "088675d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attack function defined (TRIVIAL BASELINE)\n",
      "   Students should replace the trivial implementation with sophisticated attacks!\n",
      "   Current baseline: Returns original inputs unchanged (0% success rate expected)\n",
      "\n",
      "Testing attack function...\n",
      "Original caption: A gold bus traveling on a single lane road\n",
      "Original score: 0.7833, Original label: True\n",
      "Final score: 0.4797 Final caption: A boyhood boyhood traveling on a single lane road\n",
      "Attack success: True\n"
     ]
    }
   ],
   "source": [
    "def attack(image_np_uint8: np.ndarray, caption_str: str, api: BlackBoxAPI, budgets: dict, verbose=False) -> dict:\n",
    "    \"\"\"\n",
    "    Student attack function to implement adversarial attacks.\n",
    "    \n",
    "    Args:\n",
    "        image_np_uint8: Original image as uint8 numpy array (H, W, C)\n",
    "        caption_str: Original caption string\n",
    "        api: BlackBoxAPI instance for querying the model\n",
    "        budgets: Dictionary with 'T_MAX', 'P_MAX', 'Q_MAX' limits\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with:\n",
    "        - 'success': bool, whether attack succeeded (flipped decision)\n",
    "        - 'image': np.ndarray, final attacked image  \n",
    "        - 'caption': str, final attacked caption\n",
    "        - 'token_cost': int, number of token edits used\n",
    "        - 'pixel_cost': int, number of pixel edits used\n",
    "        - 'query_cost': int, number of queries used\n",
    "    \"\"\"\n",
    "    \n",
    "    # TRIVIAL BASELINE - Students should replace this!\n",
    "    # This baseline just returns the original inputs without any attack\n",
    "    \n",
    "    original_image = image_np_uint8.copy()\n",
    "    original_caption = caption_str\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get original score to determine target (flip the decision)\n",
    "    original_score = api.score(original_image, original_caption)\n",
    "    \n",
    "\n",
    "    # For this baseline, we don't actually perform any attack\n",
    "    # Students should implement sophisticated attacks here!\n",
    "    \n",
    "    # TODO: IMPLEMENT YOUR ATTACK HERE!\n",
    "    # You can modify:\n",
    "    # - Caption tokens (text modifications)  \n",
    "    # - Image pixels (visual modifications)\n",
    "    # - Both (multimodal attack)\n",
    "    \n",
    "    # Stay within budgets:\n",
    "    # - budgets['T_MAX'] = maximum token edits\n",
    "    # - budgets['P_MAX'] = maximum pixel edits\n",
    "    # - budgets['Q_MAX'] = maximum queries\n",
    "    \n",
    "    # Attack Strategies to Consider:\n",
    "    # - Text Attacks: Synonym replacement, word insertion/deletion, semantic paraphrasing\n",
    "    # - Image Attacks: Adversarial noise, targeted pixel modifications, patch attacks\n",
    "    # - Query Optimization: Gradient-free optimization, genetic algorithms, hill climbing\n",
    "    # - Multimodal: Combined text+image attacks for maximum effectiveness\n",
    "\n",
    "    original_label = original_score > 0.5\n",
    "    final_image = original_image  # Placeholder: No image attack implemented yet\n",
    "    final_caption, final_score = caption_attack(original_caption, original_image, original_label, api)    # Comment out this line when implementing text attacks\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Original caption: {original_caption}\")\n",
    "        print(f\"Original score: {original_score:.4f}, Original label: {original_label}\")\n",
    "        print(f\"Final score: {final_score:.4f} Final caption: {final_caption}\")\n",
    "    \n",
    "    # Check if attack succeeded (decision flipped)\n",
    "    original_decision = original_score > 0.5\n",
    "    final_decision = final_score > 0.5\n",
    "    success = (original_decision != final_decision)\n",
    "    \n",
    "    # Calculate costs\n",
    "    token_cost = token_edit_cost(original_caption, final_caption)\n",
    "    pixel_cost = pixel_edit_cost(original_image, final_image)\n",
    "    query_cost = api.query_count\n",
    "    \n",
    "    return {\n",
    "        'success': success,\n",
    "        'image': final_image,\n",
    "        'caption': final_caption,\n",
    "        'token_cost': token_cost,\n",
    "        'pixel_cost': pixel_cost,  \n",
    "        'query_cost': query_cost,\n",
    "        'original_score': original_score,\n",
    "        'final_score': final_score\n",
    "    }\n",
    "\n",
    "print(\"Attack function defined (TRIVIAL BASELINE)\")\n",
    "print(\"   Students should replace the trivial implementation with sophisticated attacks!\")\n",
    "print(\"   Current baseline: Returns original inputs unchanged (0% success rate expected)\")\n",
    "\n",
    "# Test the attack function\n",
    "print(\"\\nTesting attack function...\")\n",
    "test_pair = val_pairs[0]\n",
    "test_image = np.array(load_image_from_pair(test_pair))\n",
    "\n",
    "# Create fresh API instance  \n",
    "test_api = BlackBoxAPI(alpha, beta, q_max=100)\n",
    "\n",
    "attack_budgets = {\n",
    "    'T_MAX': 10,     # Maximum token edits per sample\n",
    "    'P_MAX': 100,   # Maximum pixel edits per sample  \n",
    "    'Q_MAX': 100    # Maximum queries per sample\n",
    "}\n",
    "\n",
    "result = attack(test_image, test_pair['caption'], test_api, attack_budgets, verbose=True)\n",
    "print(f\"Attack success: {result['success']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7b71a",
   "metadata": {},
   "source": [
    "The randomness of the preprocessing makes it so the final call should be the final returned score otherwise, you cant talk about if caption succecedes or not, but if it on average \"succedes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f7a10633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on validation set...\n",
      "Running on first 50 samples for quick testing...\n",
      "Starting evaluation...\n",
      "Evaluating on 50 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking: 100%|██████████| 50/50 [00:50<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION RESULTS (50 samples):\n",
      "==================================================\n",
      "Attack Success Rate (ASR): 94.0%\n",
      "Average Number of Changes (ANC): 30.20\n",
      "Average Queries (AQ): 3.4\n",
      "Final Score: 0.8611\n",
      "==================================================\n",
      "Budget Usage:\n",
      "  Avg Token Cost: 3.02/10\n",
      "  Avg Pixel Cost: 0.00/100\n",
      "  Avg Query Cost: 3.4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Framework\n",
    "def evaluate_attack(val_pairs: list, attack_function, alpha: float, beta: float, budgets: dict, max_samples: int = None):\n",
    "    \"\"\"\n",
    "    Evaluate attack function on validation pairs.\n",
    "    \n",
    "    Args:\n",
    "        val_pairs: List of validation pairs\n",
    "        attack_function: Attack function to evaluate\n",
    "        alpha, beta: Calibrated parameters\n",
    "        budgets: Attack budgets dictionary\n",
    "        max_samples: Limit number of samples (None = all)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with evaluation metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Starting evaluation...\")\n",
    "    \n",
    "    # Limit samples if specified\n",
    "    eval_pairs = val_pairs[:max_samples] if max_samples else val_pairs\n",
    "    print(f\"Evaluating on {len(eval_pairs)} samples\")\n",
    "    \n",
    "    results = []\n",
    "    total_success = 0\n",
    "    total_token_cost = 0\n",
    "    total_pixel_cost = 0\n",
    "    total_query_cost = 0\n",
    "    \n",
    "    for i, pair in enumerate(tqdm(eval_pairs, desc=\"Attacking\")):\n",
    "        # Create fresh API instance for each sample\n",
    "        api = BlackBoxAPI(alpha, beta, q_max=budgets['Q_MAX'])\n",
    "        \n",
    "        # Load image\n",
    "        image = np.array(load_image_from_pair(pair))\n",
    "        caption = pair['caption']\n",
    "        \n",
    "        try:\n",
    "            # Run attack\n",
    "            result = attack_function(image, caption, api, budgets)\n",
    "            \n",
    "            # Validate budget constraints\n",
    "            budget_valid = (\n",
    "                result['token_cost'] <= budgets['T_MAX'] and\n",
    "                result['pixel_cost'] <= budgets['P_MAX'] and  \n",
    "                result['query_cost'] <= budgets['Q_MAX']\n",
    "            )\n",
    "            \n",
    "            if not budget_valid:\n",
    "                print(f\"Sample {i}: Budget violation!\")\n",
    "                print(f\"   Tokens: {result['token_cost']}/{budgets['T_MAX']}\")\n",
    "                print(f\"   Pixels: {result['pixel_cost']}/{budgets['P_MAX']}\")  \n",
    "                print(f\"   Queries: {result['query_cost']}/{budgets['Q_MAX']}\")\n",
    "                result['success'] = False  # Invalid attacks count as failures\n",
    "            \n",
    "            results.append(result)\n",
    "            \n",
    "            if result['success']:\n",
    "                total_success += 1\n",
    "            total_token_cost += result['token_cost']\n",
    "            total_pixel_cost += result['pixel_cost']\n",
    "            total_query_cost += result['query_cost']\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Sample {i}: Attack failed with error: {e}\")\n",
    "            # Add failed result\n",
    "            results.append({\n",
    "                'success': False,\n",
    "                'token_cost': budgets['T_MAX'],  # Penalize failures\n",
    "                'pixel_cost': budgets['P_MAX'], \n",
    "                'query_cost': budgets['Q_MAX'],\n",
    "                'error': str(e)\n",
    "            })\n",
    "    \n",
    "    # Calculate metrics\n",
    "    n_samples = len(results)\n",
    "    asr = total_success / n_samples  # Attack Success Rate\n",
    "    anc = (10*total_token_cost + total_pixel_cost) / n_samples  # Average Number of Changes  \n",
    "    aq = total_query_cost / n_samples  # Average Queries\n",
    "    \n",
    "    # Final score: ASR - 0.5*ANC - 0.1*(AQ/Q_MAX)\n",
    "    score = asr - 0.5 * (anc / (10*budgets['T_MAX'] + budgets['P_MAX'])) - 0.1 * (aq / budgets['Q_MAX'])\n",
    "    \n",
    "    evaluation_result = {\n",
    "        'ASR': asr,\n",
    "        'ANC': anc, \n",
    "        'AQ': aq,\n",
    "        'Score': score,\n",
    "        'n_samples': n_samples,\n",
    "        'total_success': total_success,\n",
    "        'avg_token_cost': total_token_cost / n_samples,\n",
    "        'avg_pixel_cost': total_pixel_cost / n_samples,\n",
    "        'budgets': budgets,\n",
    "        'results': results\n",
    "    }\n",
    "    \n",
    "    return evaluation_result\n",
    "\n",
    "# Run Evaluation\n",
    "print(\"Running evaluation on validation set...\")\n",
    "\n",
    "# Define attack budgets\n",
    "attack_budgets = {\n",
    "    'T_MAX': 10,     # Maximum token edits per sample\n",
    "    'P_MAX': 100,   # Maximum pixel edits per sample  \n",
    "    'Q_MAX': 100    # Maximum queries per sample\n",
    "}\n",
    "\n",
    "# Evaluate on subset first (faster for testing)\n",
    "print(\"Running on first 50 samples for quick testing...\")\n",
    "eval_result = evaluate_attack(\n",
    "    val_pairs=val_pairs, \n",
    "    attack_function=attack,\n",
    "    alpha=alpha,\n",
    "    beta=beta, \n",
    "    budgets=attack_budgets,\n",
    "    max_samples=50  # Quick test on 50 samples\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nEVALUATION RESULTS (50 samples):\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Attack Success Rate (ASR): {eval_result['ASR']:.1%}\")\n",
    "print(f\"Average Number of Changes (ANC): {eval_result['ANC']:.2f}\")  \n",
    "print(f\"Average Queries (AQ): {eval_result['AQ']:.1f}\")\n",
    "print(f\"Final Score: {eval_result['Score']:.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Budget Usage:\")\n",
    "print(f\"  Avg Token Cost: {eval_result['avg_token_cost']:.2f}/{attack_budgets['T_MAX']}\")\n",
    "print(f\"  Avg Pixel Cost: {eval_result['avg_pixel_cost']:.2f}/{attack_budgets['P_MAX']}\")  \n",
    "print(f\"  Avg Query Cost: {eval_result['AQ']:.1f}/{attack_budgets['Q_MAX']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a906503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FULL evaluation on all 1000 validation samples...\n",
      "This may take several minutes depending on your attack implementation.\n",
      "Starting evaluation...\n",
      "Evaluating on 1000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking:   6%|▌         | 56/1000 [00:57<16:10,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 55: Budget violation!\n",
      "   Tokens: 12/10\n",
      "   Pixels: 0/100\n",
      "   Queries: 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking:   8%|▊         | 77/1000 [01:19<15:57,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 76: Budget violation!\n",
      "   Tokens: 12/10\n",
      "   Pixels: 0/100\n",
      "   Queries: 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking:   8%|▊         | 82/1000 [01:24<15:35,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 81: Budget violation!\n",
      "   Tokens: 12/10\n",
      "   Pixels: 0/100\n",
      "   Queries: 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking:  14%|█▎        | 136/1000 [02:18<14:23,  1.00it/s]"
     ]
    }
   ],
   "source": [
    "# Full Evaluation (Uncomment when ready to test your attack)\n",
    "\n",
    "def run_full_evaluation():\n",
    "    \"\"\"Run evaluation on all 1000 validation samples.\"\"\"\n",
    "    print(\"Running FULL evaluation on all 1000 validation samples...\")\n",
    "    print(\"This may take several minutes depending on your attack implementation.\")\n",
    "    \n",
    "    full_result = evaluate_attack(\n",
    "        val_pairs=val_pairs,\n",
    "        attack_function=attack, \n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        budgets=attack_budgets,\n",
    "        max_samples=None  # All samples\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFINAL EVALUATION RESULTS:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Attack Success Rate (ASR): {full_result['ASR']:.1%}\")\n",
    "    print(f\"Average Number of Changes (ANC): {full_result['ANC']:.2f}\")\n",
    "    print(f\"Average Queries (AQ): {full_result['AQ']:.1f}\")\n",
    "    print(f\"Final Score: {full_result['Score']:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return full_result\n",
    "\n",
    "# Uncomment the line below when ready to run full evaluation:\n",
    "full_results = run_full_evaluation()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41963ede",
   "metadata": {},
   "source": [
    "## Baseline scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0498a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_attack(image_np_uint8: np.ndarray, caption_str: str, api: BlackBoxAPI, budgets: dict) -> dict:\n",
    "\n",
    "    # TRIVIAL BASELINE - Students should replace this!\n",
    "    # This baseline just returns the original inputs without any attack\n",
    "    \n",
    "    original_image = image_np_uint8.copy()\n",
    "    original_caption = caption_str\n",
    "    \n",
    "    # Get original score to determine target (flip the decision)\n",
    "    original_score = api.score(original_image, original_caption)\n",
    "\n",
    "    final_image = original_image        # Comment out this line when implementing image attacks\n",
    "    final_caption = original_caption    # Comment out this line when implementing text attacks\n",
    "    \n",
    "    # Get final score  \n",
    "    final_score = api.score(final_image, final_caption)\n",
    "    \n",
    "    # Check if attack succeeded (decision flipped)\n",
    "    original_decision = original_score > 0.5\n",
    "    final_decision = final_score > 0.5\n",
    "    success = (original_decision != final_decision)\n",
    "    \n",
    "    # Calculate costs\n",
    "    token_cost = token_edit_cost(original_caption, final_caption)\n",
    "    pixel_cost = pixel_edit_cost(original_image, final_image)\n",
    "    query_cost = api.query_count\n",
    "    \n",
    "    return {\n",
    "        'success': success,\n",
    "        'image': final_image,\n",
    "        'caption': final_caption,\n",
    "        'token_cost': token_cost,\n",
    "        'pixel_cost': pixel_cost,  \n",
    "        'query_cost': query_cost,\n",
    "        'original_score': original_score,\n",
    "        'final_score': final_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f15b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running evaluation on validation set...\n",
      "Running on first 50 samples for quick testing...\n",
      "Starting evaluation...\n",
      "Evaluating on 50 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking: 100%|██████████| 50/50 [00:01<00:00, 28.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EVALUATION RESULTS (50 samples):\n",
      "==================================================\n",
      "Attack Success Rate (ASR): 0.0%\n",
      "Average Number of Changes (ANC): 0.00\n",
      "Average Queries (AQ): 2.0\n",
      "Final Score: -0.0020\n",
      "==================================================\n",
      "Budget Usage:\n",
      "  Avg Token Cost: 0.00/10\n",
      "  Avg Pixel Cost: 0.00/100\n",
      "  Avg Query Cost: 2.0/100\n",
      "\n",
      "NOTE: This is a trivial baseline (0% ASR expected)\n",
      "Students should implement sophisticated attacks to improve ASR!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Run Evaluation\n",
    "print(\"Running evaluation on validation set...\")\n",
    "\n",
    "# Define attack budgets\n",
    "attack_budgets = {\n",
    "    'T_MAX': 10,     # Maximum token edits per sample\n",
    "    'P_MAX': 100,   # Maximum pixel edits per sample  \n",
    "    'Q_MAX': 100    # Maximum queries per sample\n",
    "}\n",
    "\n",
    "# Evaluate on subset first (faster for testing)\n",
    "print(\"Running on first 50 samples for quick testing...\")\n",
    "eval_result = evaluate_attack(\n",
    "    val_pairs=val_pairs, \n",
    "    attack_function=baseline_attack,\n",
    "    alpha=alpha,\n",
    "    beta=beta, \n",
    "    budgets=attack_budgets,\n",
    "    max_samples=50  # Quick test on 50 samples\n",
    ")\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nEVALUATION RESULTS (50 samples):\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Attack Success Rate (ASR): {eval_result['ASR']:.1%}\")\n",
    "print(f\"Average Number of Changes (ANC): {eval_result['ANC']:.2f}\")  \n",
    "print(f\"Average Queries (AQ): {eval_result['AQ']:.1f}\")\n",
    "print(f\"Final Score: {eval_result['Score']:.4f}\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Budget Usage:\")\n",
    "print(f\"  Avg Token Cost: {eval_result['avg_token_cost']:.2f}/{attack_budgets['T_MAX']}\")\n",
    "print(f\"  Avg Pixel Cost: {eval_result['avg_pixel_cost']:.2f}/{attack_budgets['P_MAX']}\")  \n",
    "print(f\"  Avg Query Cost: {eval_result['AQ']:.1f}/{attack_budgets['Q_MAX']}\")\n",
    "print(f\"\\nNOTE: This is a trivial baseline (0% ASR expected)\")\n",
    "print(f\"Students should implement sophisticated attacks to improve ASR!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307d8f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FULL evaluation on all 1000 validation samples...\n",
      "This may take several minutes depending on your attack implementation.\n",
      "Starting evaluation...\n",
      "Evaluating on 1000 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attacking: 100%|██████████| 1000/1000 [00:36<00:00, 27.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FINAL EVALUATION RESULTS:\n",
      "============================================================\n",
      "Attack Success Rate (ASR): 0.3%\n",
      "Average Number of Changes (ANC): 0.00\n",
      "Average Queries (AQ): 2.0\n",
      "Final Score: 0.0010\n",
      "============================================================\n",
      "To run full evaluation on all 1000 samples:\n",
      "Uncomment: full_results = run_full_evaluation()\n",
      "\n",
      "Current status: Framework ready for student implementations!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Full Evaluation (Uncomment when ready to test your attack)\n",
    "\n",
    "def run_full_evaluation():\n",
    "    \"\"\"Run evaluation on all 1000 validation samples.\"\"\"\n",
    "    print(\"Running FULL evaluation on all 1000 validation samples...\")\n",
    "    print(\"This may take several minutes depending on your attack implementation.\")\n",
    "    \n",
    "    full_result = evaluate_attack(\n",
    "        val_pairs=val_pairs,\n",
    "        attack_function=baseline_attack, \n",
    "        alpha=alpha,\n",
    "        beta=beta,\n",
    "        budgets=attack_budgets,\n",
    "        max_samples=None  # All samples\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFINAL EVALUATION RESULTS:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Attack Success Rate (ASR): {full_result['ASR']:.1%}\")\n",
    "    print(f\"Average Number of Changes (ANC): {full_result['ANC']:.2f}\")\n",
    "    print(f\"Average Queries (AQ): {full_result['AQ']:.1f}\")\n",
    "    print(f\"Final Score: {full_result['Score']:.4f}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    return full_result\n",
    "\n",
    "# Uncomment the line below when ready to run full evaluation:\n",
    "full_results = run_full_evaluation()\n",
    "\n",
    "print(\"To run full evaluation on all 1000 samples:\")\n",
    "print(\"Uncomment: full_results = run_full_evaluation()\")\n",
    "print(\"\\nCurrent status: Framework ready for student implementations!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
